ğŸ‰ OPC UA Processor Suite
for Snowflake OpenFlow / Apache NiFi (Python NAR Extensions)

Version: 2025.10
Namespace: net.ksmcloud.opcua.processors.*
Author: Kevin Mahnke
License: MIT

ğŸ§© Overview

The OPC UA Processor Suite provides a complete set of custom OpenFlow / Apache NiFi Python processors for integrating industrial OPC UA data directly into Snowflake or any downstream data pipeline.

Built for Industry 4.0, Unified Namespace (UNS), and IIoT edge connectivity, these processors deliver full coverage from metadata discovery and historical reads to real-time subscriptions and command writes â€” with asyncua-based OPC UA client support and Snowflake-ready output.

This suite forms the core of a UNS ingestion and governance layer for oil & gas, manufacturing, and industrial automation systems.

âš™ï¸ Processors Included
Processor	Purpose	Typical Use
ğŸ§­ OPCUAGetNodeData	Browse OPC UA servers and discover node hierarchies (metadata).	Building UNS model layers, tag lineage, and data catalogs.
ğŸ“ˆ OPCUAGetData	Read current values from one or more OPC UA NodeIds.	One-shot tag polling or scheduled asset snapshots.
ğŸ•°ï¸ OPCUAHistoryRead	Retrieve time-series history from servers that support OPC UA Historical Access (HA).	Backfilling Snowflake tables with time-aligned historical values.
ğŸ”„ OPCUASubscribe	Continuous live subscription to NodeIds with client/server deadband filters.	Real-time telemetry streaming into UNS or Snowflake bronze.
âœï¸ OPCUAWriteData	Write values back to OPC UA nodes.	Closed-loop control, digital twin updates, or remote overrides.
ğŸ§  Design Goals
Goal	Description
ğŸ§± Modular	Each processor is standalone yet interoperable â€” you can chain them seamlessly.
ğŸ§° Discoverable	All processors are fully visible in the OpenFlow UI even without optional dependencies.
ğŸ”’ Secure	Supports secure sessions, credentials, and Snowflake connector encryption.
ğŸ§  Smart Server URI Handling	Unified logic for ServerUri auto-discovery, override, and encoded/raw/empty modes.
â„ï¸ Snowflake-Native Output	Each processor can emit directly to Snowflake or as JSON/CSV/XML flow files.
ğŸ§¾ Standards-Aligned	Designed around ISA-95, OPC UA Part 3, and Unified Namespace concepts.
âš™ï¸ Minimal Dependencies	Only asyncua + cryptography are required; others are optional for analytics/sinks.
ğŸ§© Architecture Overview
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚                       OPC UA Processor Suite                    â”‚
 â”‚                                                                â”‚
 â”‚  [ OPCUAGetNodeData ] â†’ [ OPCUAGetData ] â†’ [ OPCUASubscribe ]  â”‚
 â”‚               â”‚                    â”‚                â”‚           â”‚
 â”‚          Metadata          Current Values       Real-time       â”‚
 â”‚                                                                â”‚
 â”‚  [ OPCUAHistoryRead ]  â†â†’  [ OPCUAWriteData ]                   â”‚
 â”‚     Historical Backfill       Command / Control                 â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

 â†’  All outputs compatible with Snowflake, JSON, CSV, or XML sinks.
 â†’  Ideal for building multi-tier UNS models: raw â†’ bronze â†’ silver â†’ gold.

ğŸ§¾ Output Formats

All processors support consistent serialization modes:

Format	Description	MIME Type
JSON	Default structured payload for flowfile transmission.	application/json
CSV	Tabular row format with optional header.	text/csv
XML	Hierarchical data exchange format.	application/xml
Snowflake Sink	Writes directly into Snowflake tables using write_pandas.	application/json (summary)
ğŸ§Š Snowflake Integration

All processors optionally support direct Snowflake writes with auto-schema creation.
Typical schema for data tables:

Column	Type	Description
NODE_ID	STRING	OPC UA NodeId
VALUE	VARIANT	OPC UA value (numeric, string, boolean, etc.)
STATUS	STRING	OPC UA StatusCode name
SOURCE_TS	TIMESTAMP_TZ	Source timestamp (from device/server)
ENDPOINT	STRING	OPC UA server endpoint
INGEST_TS	TIMESTAMP_TZ	Time of ingestion into Snowflake

Configuration fields:

SF Account     = <account>.snowflakecomputing.com
SF User        = <user>
SF Password    = <password>
SF Warehouse   = COMPUTE_WH
SF Database    = OPCUA_DB
SF Schema      = PUBLIC
SF Table       = OPCUA_EVENTS
SF Auto-Create Table = true

ğŸ§± Example UNS Data Flow

Level 1 â€“ Metadata Discovery

[OPCUAGetNodeData] â†’ [Transform â†’ PutSnowflake]
â†’ Produces tag hierarchies and class metadata.


Level 2 â€“ Snapshot Values

[OPCUAGetData] â†’ [PutSnowflake]
â†’ Captures current readings for scheduled sampling.


Level 3 â€“ Historical Backfill

[OPCUAHistoryRead] â†’ [PutSnowflake]
â†’ Retrieves long-term historical data for analytics.


Level 4 â€“ Live Stream

[OPCUASubscribe] â†’ [Snowflake Sink / Streamlit Dashboard]
â†’ Publishes real-time data changes continuously.


Level 5 â€“ Command Writes

[GenerateCommand] â†’ [OPCUAWriteData]
â†’ Sends setpoints or control signals to devices.

ğŸ§° Dependencies (common across suite)
asyncua>=1.0.0,<2.0.0
cryptography>=41,<43
pandas>=2,<3
pyarrow>=14,<19
snowflake-connector-python>=3,<5

ğŸ—ï¸ Build & Deploy
Hatch / hatch-datavolo-nar Configuration
[tool.hatch.build.targets.nar]
sources = ["src"]
packages = ["processors"]

entry_points = [
  "net.ksmcloud.opcua.processors.OPCUAGetNodeData = processors.opcua_get_node_data:OPCUAGetNodeData",
  "net.ksmcloud.opcua.processors.OPCUAGetData = processors.opcua_get_data:OPCUAGetData",
  "net.ksmcloud.opcua.processors.OPCUAHistoryRead = processors.opcua_history_read:OPCUAHistoryRead",
  "net.ksmcloud.opcua.processors.OPCUASubscribe = processors.opcua_subscribe:OPCUASubscribe",
  "net.ksmcloud.opcua.processors.OPCUAWriteData = processors.opcua_write_data:OPCUAWriteData"
]

Directory Layout
src/
 â””â”€â”€ processors/
      â”œâ”€â”€ opcua_get_node_data.py
      â”œâ”€â”€ opcua_get_data.py
      â”œâ”€â”€ opcua_history_read.py
      â”œâ”€â”€ opcua_subscribe.py
      â””â”€â”€ opcua_write_data.py

Build Command
hatch build -t nar

Deploy

Copy the generated NAR(s) into:

/opt/runtime/extensions/


Restart your OpenFlow / NiFi runtime.
All processors will appear under the â€œDraconis Integrations â€” OPC UAâ€ category.

ğŸ§­ Example Canvas Usage

Add Processor â†’ OPCUAGetNodeData
Discover namespace & export metadata.

Add Processor â†’ OPCUAGetData
Read current tag values for specific NodeIds.

Add Processor â†’ OPCUASubscribe
Subscribe to live values; route results to Snowflake or file.

Add Processor â†’ OPCUAHistoryRead
Retrieve historical tag data by time range.

Add Processor â†’ OPCUAWriteData
Push control values back to connected OPC UA servers.

ğŸ§± Example UNS Snowflake Schema
Layer	Table	Description
raw	OPCUA_EVENTS_RAW	Direct event streams from OPCUASubscribe.
bronze	OPCUA_TAGS	Flattened tag/value tables from GetData.
silver	OPCUA_HISTORY	Time-series history from HistoryRead.
gold	UNS_MODEL	Hierarchical node metadata from GetNodeData.
ğŸ§° Troubleshooting
Issue	Likely Cause / Fix
BadServerUriInvalid	Switch Server URI Mode to encoded or raw.
Processor not visible in UI	Ensure __all__ and FlowFileSource definitions exist.
No data received	Verify NodeIds and endpoint URL; check port/firewall.
Snowflake errors	Confirm credentials and warehouse/database/schema/table exist.
UI lag	Reduce Browse Depth or subscription Buffer Events.
Large data bursts	Use CSV or Snowflake sink instead of JSON for efficiency.
ğŸ§¾ License

MIT License Â©
Free for commercial and industrial use.